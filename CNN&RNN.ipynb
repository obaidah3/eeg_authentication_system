{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc3UIJ1M6-Fn",
        "outputId": "7276f2cf-e367-40b7-8fad-7429b70c5181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths (adjust if needed)\n",
        "SEGMENTS_DIR = \"/content/drive/MyDrive/files/segments\" # where .npy segments are stored\n",
        "META_CSV = os.path.join(SEGMENTS_DIR, 'metadata.csv')\n",
        "MODEL_SAVE = '/content/drive/MyDrive/files/best_cnn_rnn.pth'\n",
        "os.makedirs(SEGMENTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "DrEGKDqJ8I4k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build metadata if missing\n",
        "if not os.path.exists(META_CSV):\n",
        "    records = []\n",
        "    for f in sorted(glob(os.path.join(SEGMENTS_DIR, '*.npy'))):\n",
        "        fname = os.path.basename(f)\n",
        "        # expected pattern: Sxxx_<orig>_segN.npy\n",
        "        parts = fname.split('_')\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        subj = parts[0]\n",
        "        session = 1\n",
        "        # try to detect session in filename\n",
        "        for p in parts:\n",
        "            if p.lower().startswith('session'):\n",
        "                try:\n",
        "                    session = int(p.replace('session',''))\n",
        "                except:\n",
        "                    session = 1\n",
        "        # subject like S001 -> label 0\n",
        "        label = int(subj.replace('S','')) - 1\n",
        "        records.append({'path': f, 'label': label, 'session': session})\n",
        "    meta = pd.DataFrame.from_records(records)\n",
        "    meta.to_csv(META_CSV, index=False)\n",
        "    print('Created metadata.csv with', len(meta), 'entries')\n",
        "else:\n",
        "    meta = pd.read_csv(META_CSV)\n",
        "    print('Loaded metadata.csv with', len(meta), 'entries')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F4B--a78Qub",
        "outputId": "f49de624-feca-48cf-f2c8-9e8018d18e3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created metadata.csv with 32029 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: compute spectrogram per segment on-the-fly\n",
        "class EEGSpectrogramDataset(Dataset):\n",
        "    def __init__(self, meta_df, sample_rate=160, n_fft=256, hop=64, freq_range=(1,50), transform=None):\n",
        "        self.meta = meta_df.reset_index(drop=True)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.n_fft = n_fft\n",
        "        self.hop = hop\n",
        "        self.freq_range = freq_range\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.meta.iloc[idx]\n",
        "        arr = np.load(row['path']).astype(np.float32)  # (C, T)\n",
        "        x = torch.from_numpy(arr)\n",
        "        # channel-wise STFT -> magnitude\n",
        "        specs = []\n",
        "        for ch in range(x.shape[0]):\n",
        "            stft = torch.stft(x[ch], n_fft=self.n_fft, hop_length=self.hop, win_length=self.n_fft, center=True, return_complex=True)\n",
        "            mag = stft.abs()\n",
        "            specs.append(mag.unsqueeze(0))\n",
        "        spec = torch.cat(specs, dim=0)  # (C, F, Tfr)\n",
        "        freqs = torch.linspace(0, self.sample_rate / 2, steps=(self.n_fft // 2 + 1))\n",
        "        fmin, fmax = self.freq_range\n",
        "        fmask = (freqs >= fmin) & (freqs <= fmax)\n",
        "        spec = spec[:, fmask, :]\n",
        "        spec = torch.log1p(spec)\n",
        "        label = int(row['label'])\n",
        "        session = int(row['session']) if 'session' in row else 1\n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "        return spec, label, session"
      ],
      "metadata": {
        "id": "sACkfKCt8Xq5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Hybrid Model\n",
        "# CNN encoder produces timewise features -> GRU processes temporal sequence\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, in_ch, cnn_channels=(32,64,128)):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = in_ch\n",
        "        for outc in cnn_channels:\n",
        "            layers += [\n",
        "                nn.Conv2d(prev, outc, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(outc),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d((2,2))\n",
        "            ]\n",
        "            prev = outc\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class HybridCNNRNN(nn.Module):\n",
        "    def __init__(self, in_ch, n_freq_bins, cnn_channels=(32,64,128), gru_hidden=256, gru_layers=2, n_classes=109, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.encoder = CNNEncoder(in_ch, cnn_channels=cnn_channels)\n",
        "        # compute feature dim after cnn pooling for freq dimension\n",
        "        # assume freq dimension is divisible by 2**len(cnn_channels)\n",
        "        self.freq_reduction = 2 ** len(cnn_channels)\n",
        "        feat_dim = cnn_channels[-1] * (n_freq_bins // self.freq_reduction)\n",
        "        self.gru = nn.GRU(input_size=feat_dim, hidden_size=gru_hidden, num_layers=gru_layers, batch_first=True, bidirectional=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(gru_hidden*2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, F, T)\n",
        "        out = self.encoder(x)  # (B, C', F', T')\n",
        "        B, C1, Fp, Tp = out.shape\n",
        "        out = out.permute(0, 3, 1, 2).contiguous()  # (B, Tp, C', F')\n",
        "        out = out.view(B, Tp, C1 * Fp)  # (B, Tp, feat)\n",
        "        gru_out, _ = self.gru(out)\n",
        "        pooled = gru_out.mean(dim=1)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "ByKEfs798z-5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train / Eval helpers\n",
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_epoch(model, loader, optim, device):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    all_preds, all_labels = [], []\n",
        "    for spec, label, _ in tqdm(loader, desc='train', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        label = label.to(device)\n",
        "        optim.zero_grad()\n",
        "        out = model(spec)\n",
        "        loss = F.cross_entropy(out, label)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        losses.append(loss.item())\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(label.cpu().numpy().tolist())\n",
        "    return np.mean(losses), accuracy_score(all_labels, all_preds)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    probs_list = []\n",
        "    labels = []\n",
        "    for spec, label, _ in tqdm(loader, desc='eval', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        out = model(spec)\n",
        "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
        "        probs_list.append(probs)\n",
        "        labels.extend(label.numpy().tolist())\n",
        "    probs = np.concatenate(probs_list, axis=0)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    top1 = accuracy_score(labels, preds)\n",
        "    try:\n",
        "        top5 = top_k_accuracy_score(labels, probs, k=5)\n",
        "    except Exception:\n",
        "        top5 = None\n",
        "    return top1, top5\n"
      ],
      "metadata": {
        "id": "YaJmRoGr86Kk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare splits, dataloaders\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform a random train-test split on the entire metadata\n",
        "train_meta, test_meta = train_test_split(meta, test_size=0.2, random_state=42, stratify=meta['label'])\n",
        "\n",
        "train_meta = train_meta.reset_index(drop=True)\n",
        "test_meta = test_meta.reset_index(drop=True)\n",
        "\n",
        "print(f'Train samples: {len(train_meta)}')\n",
        "print(f'Test samples: {len(test_meta)}')\n",
        "\n",
        "train_ds = EEGSpectrogramDataset(train_meta)\n",
        "test_ds = EEGSpectrogramDataset(test_meta)\n",
        "\n",
        "# quick dimension probe\n",
        "spec0, _, _ = train_ds[0]\n",
        "C, n_freq_bins_val, T = spec0.shape # Renamed F to n_freq_bins_val\n",
        "print('Spec shape per sample:', spec0.shape)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzWxoz6E87rH",
        "outputId": "66681ef3-7f32-4ea3-9aa5-de8ed3d0eb11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 25623\n",
            "Test samples: 6406\n",
            "Spec shape per sample: torch.Size([64, 79, 6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:681: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:836.)\n",
            "  return _VF.stft(  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HybridCNNRNN(in_ch=C, n_freq_bins=n_freq_bins_val, n_classes=109, cnn_channels=(32,64)).to(device) # Changed F to n_freq_bins_val\n",
        "optim = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=8, gamma=0.5)\n"
      ],
      "metadata": {
        "id": "k7r-ZhYs8-Tl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best = 0.0\n",
        "epochs = 10\n",
        "for ep in range(1, epochs+1):\n",
        "    loss, train_acc = train_epoch(model, train_loader, optim, device)\n",
        "    top1, top5 = evaluate(model, test_loader, device)\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {ep:02d} loss={loss:.4f} train_acc={train_acc:.3f} test_top1={top1:.3f} test_top5={top5}')\n",
        "    if top1 > best:\n",
        "        best = top1\n",
        "        torch.save(model.state_dict(), MODEL_SAVE)\n",
        "        print('Saved best model ->', MODEL_SAVE)\n",
        "\n",
        "print('Training complete. Best test top1:', best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjZK_Vso9Ky9",
        "outputId": "0741ed3b-5052-4c5c-b736-8ad6bb4af1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain:   0%|          | 0/1602 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute per-subject accuracy and save a simple report\n",
        "@torch.no_grad()\n",
        "def per_subject_accuracy(model, loader, device, meta_df):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    paths = []\n",
        "    for spec, label, _ in tqdm(loader, desc='per-subject', leave=False):\n",
        "        spec = spec.to(device)\n",
        "        out = model(spec)\n",
        "        p = out.argmax(dim=1).cpu().numpy()\n",
        "        preds.extend(p.tolist())\n",
        "        labels.extend(label.numpy().tolist())\n",
        "    df = pd.DataFrame({'label': labels, 'pred': preds})\n",
        "    accs = df.groupby('label').apply(lambda d: (d['label']==d['pred']).mean())\n",
        "    accs = accs.sort_values()\n",
        "    accs.to_csv(os.path.join(os.path.dirname(MODEL_SAVE), 'per_subject_acc.csv'))\n",
        "    print('Saved per-subject accuracies.')"
      ],
      "metadata": {
        "id": "o5ulklbI9MJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load best model and run per-subject report\n",
        "model.load_state_dict(torch.load(MODEL_SAVE, map_location=device))\n",
        "per_subject_accuracy(model, test_loader, device, test_meta)\n",
        "print('Report saved near model file.')\n"
      ],
      "metadata": {
        "id": "8_IU4IKU9PPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XhsYlxl19Q31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}